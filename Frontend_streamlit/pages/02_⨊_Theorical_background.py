import streamlit as st
import base64
from PIL import Image
import pandas as pd
import numpy as np
import s3fs
import plotly.express as px
import io

st.set_page_config(
    page_title="Hello Mushroom-dawan",
    page_icon="üçÑ",
    layout="wide")

fs = s3fs.S3FileSystem(anon=False)
image_path = ("imagemobucket/Streamlit/Figure_project/")
df_path = ("imagemobucket/Csv/")
image_path_gif = ("imagemobucket/Streamlit/Gif/")

@st.cache_data(ttl=600)
def read_image_bucket(filename):
    return Image.open(fs.open(filename))


@st.cache_data(ttl=600)
def read_file(filename):
    with fs.open(filename, 'rb') as f:
        return f.read()

@st.cache_data
def read_csv_st(filename , sep_st):
        return pd.read_csv(fs.open(filename), sep= sep_st)
path = (df_path + 'GBIF_tax.csv')
df = read_csv_st(path ,sep_st='\t')
df2 = read_csv_st(df_path + "All_ranks_and_occurence.csv",sep_st=',')




choice = st.sidebar.radio("Submenu", ["Introduction","Donn√©es", "Montage des machines virtuelles", "Classification", "Interpr√©tabilit√©"])
if choice == 'Introduction':
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title('Rapport de projet')
        c1, c2, c3, c4 = st.columns(4, gap="large")
    st.markdown("""---""")


    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.title('Contexte')
        st.markdown("---")
        st.write("""Il existe diff√©rentes techniques permettant d‚Äôidentifier des esp√®ces de champignons. La plus utilis√©e et la plus ancienne est l'identification morphologique, qui classifie les individus par leurs caract√©ristiques anatomiques. Cependant, cette technique a l'inconv√©nient d‚Äô√™tre limit√©e en termes de pr√©cision car d√©pendante de l'observation et du protocole d'identification de la personne qui la pratique.""")
        st.write("")
        st.write("")
        st.write("")
        st.write("""L‚Äôobjectif du projet ¬´¬†Reconnaissance de champignons¬†¬ª √©tait de faire de la reconnaissance automatis√©e de champignons au travers des technologies de Computer Vision. Il s‚Äôinscrivait dans le cadre de la formation Data Scientist dispens√©e par la soci√©t√© DataScientest et constituait pour nous une premi√®re exp√©rience professionnelle en vue de valoriser nos connaissances et de monter en comp√©tence dans le domaine de la Data Science. Plus pr√©cis√©ment, ce projet s‚Äôinscrivait dans le domaine de la computer vision et avait pour objectif d‚Äôacqu√©rir des connaissances sur les technologies de Deep Learning.""")
        
if choice == 'Donn√©es':
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title('Rapport de projet')
        c1, c2, c3, c4 = st.columns(4, gap="large")
    st.markdown("""---""")



    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.title('Donn√©es')
        st.write("")
        st.write("""Pour le projet nous avons travaill√© avec des images t√©l√©charg√©es depuis les bases de donn√©es disponibles sur le site https://www.gbif.org/. GBIF est un projet scientifique visant √† r√©pertorier l‚Äôensemble des donn√©es taxonomiques sur la biodiversit√©, dont le Royaume Fungi. Le portail du GBIF expose une API permettant de t√©l√©charger des photos d‚Äôesp√®ces vivantes √† partir d‚Äôune clef taxonomique. Il existe, sur le site GBIF, un fichier qui permet de lier les clefs taxonomiques aux noms des esp√®ces ainsi qu‚Äô√† leurs taxonomies compl√®tes. Voici quelques lignes du fichier GBIF_tax.csv pour les entr√©es appartenant au Kingdom Fungi.""")
        st.write("")
        st.write("")
        st.write("")
        expander = st.expander("Mushrooms DataFrame")
        
        expander.dataframe(df)
        expander.write("""La colonne numberOfOccurences indique le nombre d‚Äôimages disponibles pour chaque esp√®ce. Au total la source expose environ 34 M de photos de champignons.""")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2: 
        st.title("Exploration de donn√©es")
        st.write("")
        st.write("""La premi√®re √©tape √©tait de d√©finir notre jeu de donn√©es. Il √©tait n√©cessaire de d√©finir les classes √† utiliser pour entrainer un mod√®le. Une photo repr√©sente un champignon qui est d√©finit par son nom ainsi que par sa taxonomie. En biologie, une taxonomie est un moyen de d√©finir des groupes hi√©rarchiques bas√©s sur des caract√©ristiques communes (voir figure).  Plus on descend dans un arbre taxonomique plus l‚Äôidentification devient sp√©cifique.  """)
        st.write("")
        st.write("")
        st.write("")
    col5, col6, col7, col8 = st.columns([0.5,4,4,0.5])
    with col6 : 
        st.image(read_image_bucket( image_path + 'tax_black.png'),channels="RGB", output_format="auto")
    st.markdown("""---""")
    with col7: 
        st.write("""Dans le tableau nous trouvons la colonne taxonRank qui indique le dernier niveau atteint dans l‚Äôidentification des photos des champignons pour une certaine taxonKey. A chaque rang taxonomique (ex¬†: Family) nous trouvons un certain nombre de classe, nombre qui augmente exponentiellement lorsque nous descendons dans l‚Äôarbre. La figure ci-dessous est un sunburst repr√©sentant l‚Äôensemble des rangs taxonomique (en partant du Kingdom Fungi) ainsi que l‚Äôensemble des classes dans chaque rang.""")
    st.write("")
    st.write("")

    df4 = df.dropna(subset = ['kingdom', 'phylum', 'class','order','family','genus'])
    fig2 = px.sunburst(df4, path=['kingdom','phylum','class','order','family','genus'],values=df4.numberOfOccurrences,maxdepth=3,color_discrete_sequence=px.colors.qualitative.T10)
    c1,c2,c3 = st.columns([0.2,4,0.2])
    with c2: 
        st.plotly_chart(fig2 ,width= 900) 
        
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:
        

        st.write("La figure ci-dessous, quant √† elle, repr√©sente le nombre de classes disponibles dans chaque rang taxonomique.")
              
    c1,c2,c3 = st.columns([0.5,1,0.5])
    with c2:
        df_forbar = df2.groupby("rank").count().sort_values(by='occurence')
        df_forbar['rank'] = df_forbar.index.values
        fig3 = px.bar(data_frame=df_forbar,x='rank',y='occurence',barmode='group',log_y=True,hover_data=["occurence"],
             labels={'rank':'Rang taxonomique','occurence':'Nombre de taxons'},title="Nombre de taxons √† chaque rang taxonomique")
        st.plotly_chart(fig3)

        st.write("")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:
        st.write("""Ces figures permettent de mettre en avant une des principales probl√©matiques du projet¬†: le nombre faramineux d‚Äôesp√®ces de champignons diff√©rentes. En effet, sur GBIF, nous trouvons 117¬†539 esp√®ces de champignon. Une √©tude de l‚Äô√©tat de l‚Äôart sur la classification par Computer Vision montre qu‚Äôun mod√®le capable d‚Äôidentifier autant de classes est aujourd‚Äôhui hors de port√©e technologiquement parlant.""")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:  
        st.write("")
        st.write("")
        st.write("""Afin de r√©duire le nombre de classe disponible, il peut para√Ætre judicieux de se placer haut dans l‚Äôarbre taxonomique. Par exemple, il existe uniquement 7 Phylums diff√©rents pour les champignons. Cependant, en travaillant haut dans l‚Äôarbre taxonomique, nous nous retrouvons avec des classes tr√®s g√©n√©rales, dans lesquelles les champignons peuvent √™tre tr√®s diff√©rents. Un exemple est donn√© dans la figure ci-dessous sur laquelle nous pr√©sentons deux champignons appartenant √† la m√™me Family¬†: Agaricaceae.  """)
    st.write("")
    st.write("")
    col5, col6, col7 = st.columns([0.5,8,0.5])
    with col6 : 
        st.image(read_image_bucket( image_path + 'Agaricaceae.png'),channels="RGB", output_format="auto")
    
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:
        st.write("""Nous avons estim√© que travailler avec de telles donn√©es pourrait rendre l‚Äôapprentissage tr√®s difficile, car nous demandons au mod√®le de regrouper dans la m√™me classe des images tr√®s diff√©rentes.  """)
        st.write("")
        st.write("")
        st.write("""Finalement, nous avons d√©cid√© de travailler √† la maille Species afin d‚Äôavoir, dans une m√™me classe, des champignons qui se ressemblent, m√™me si cela entraine une augmentation du nombre de classes disponibles. Pour le nombre de classes, nous nous sommes fix√©s comme objectif de travailler avec les 100 classes les plus repr√©sent√©es dans GBIF. La figure ci-dessous montre le nombre d‚Äôimages disponibles pour chacune de ces classes.
""")
    st.write("")
    st.write("")
    
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:
        st.write("""Ici, nous voyons que le nombre d‚Äôimages disponible ne posera pas de probl√®me. Il est m√™me n√©cessaire de se restreindre afin de pouvoir entrainer des mod√®les sur nos machines dans des temps acceptables. Nous avons donc choisi de travailler avec environ 500 images par esp√®ces, soit un total de 50000 images.""")
    
    dft = df2 
    dft_temp = dft[dft['rank'] == 'Species'].head(100)
    fig4 = px.bar(data_frame=dft_temp,x='name',y='occurence',barmode='group',log_y=False,hover_data=["occurence"],color="occurence",
             labels={'name':'Taxon','occurence':"Nombre d'images"},title="Nombre d'images disponibles pour les 100 premiers taxon du rang Species", height=800, width=1400)
    st.plotly_chart(fig4)


if choice == 'Montage des machines virtuelles':
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title('Rapport de projet')
    st.markdown("""---""")
    expander3 = st.expander("Dans le cadre de notre projet voici le mod√®le de machine virtuelle que nous avons souhait√© d√©velopper :") 
    with st.expander("Dans le cadre de notre projet voici le mod√®le de machine virtuelle que nous avons souhait√© d√©velopper :") :
        col1, col2, col3 = st.columns([0.5,2,0.5])
        with col2:
            st.image(read_image_bucket( image_path + 'DE_big.png'),channels="RGB", output_format="auto", use_column_width = 'auto')
            """
* Frontend : 
  * Streamlit permettant la r√©ception d'image classifier
    * Host = EC2 Public
* Backend : 
  * Classification des photos re√ßues par le Streamlit
    * Host = EC2 Priv√©
        * T√©lechargement des images de la base MO
        * T√©lechargement des images de la base GBIF
        * Mise √† jour des donn√©es re√ßues sur la base MO
        * Calculs des mod√®les de pr√©diction NVIDIA
"""

    st.markdown("""---""")

    expander3 = st.expander("Pour optimiser notre temps sur les mod√®les, nous avons finalement effectu√© cette architecture :") 
    with st.expander("Pour optimiser notre temps sur les mod√®les, nous avons finalement effectu√© cette architecture :") :
        col1, col2, col3 = st.columns([0.5,2,0.5])
        with col2:
            st.image(read_image_bucket( image_path + 'DE_small.png'),channels="RGB", output_format="auto", use_column_width = 'auto')
            """
* Frontend : 
  * Streamlit permettant la r√©ception d'image classifier
    * Host = EC2 Public
* Backend : 
  * Classification des photos re√ßues par le Streamlit
    * Host = EC2 Priv√©
        * T√©lechargement des images de la base GBIF
        * Mise √† jour des donn√©es re√ßues sur la base MO
"""


if choice == 'Classification':
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title('Rapport de projet')
        c1, c2, c3, c4 = st.columns(4, gap="large")
    st.markdown("""---""")



    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.title('M√©thodes')
        st.write("")
        st.write("""Comme mentionn√© pr√©c√©demment, ce projet vise √† identifier des images de champignons. Ce proc√©d√© est un probl√®me typique de classification d'images, g√©n√©ralement trait√© par des m√©thodes de Deep Learning et plus sp√©cifiquement √† l‚Äôaide de r√©seaux de neurones convolutifs (CNN). De plus, il est aujourd‚Äôhui d‚Äôusage d‚Äôutiliser les m√©thodes d‚Äôapprentissage par transfert (transfer learning) afin de r√©duire consid√©rablement le temp d‚Äôentrainement des mod√®les.""")
        st.write("")
        st.write("")
        st.write("")
        st.write("")
        st.write("""Le principe est simple, nous utilisons le savoir acquis par des mod√®les entrain√©s sur des machines tr√®s puissantes et pendant des temps longs pour une t√¢che particuli√®re afin de r√©soudre un probl√®me diff√©rent mais qui pr√©sente des similitudes. Pour les CNN, il existe aujourd‚Äôhui de nombreux mod√®les (VGG, MobileNet, ResNet, DenseNet, etc.) qui ont √©t√© entra√Æn√©s sur le jeu de donn√©es ImageNet, compos√© de 1000 classes et de 1¬†281 167 images. Le principe de l‚Äôapprentissage par transfert (repr√©sent√© sur la figure ci-dessous) est d‚Äôinterfacer la partie convolutive des mod√®les dit pr√©-entra√Æn√©s ainsi que leurs poids avec notre propre classifieur (couches de neurones denses dans notre cas), adapt√© √† notre probl√®me. Nous utilisons alors la partie convolutive du mod√®le comme extracteur de features d√©j√† tr√®s bien entra√Æn√©, permettant ainsi d‚Äôobtenir rapidement de bons r√©sultats.
""")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([1,6,1])    
    with col2:
        st.image(read_image_bucket( image_path + 'TF_black.png'),channels="RGB", output_format="auto")
        st.write("")
        st.write("")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:  
        st.write("""L‚Äôentrainement d‚Äôun tel mod√®le se fait g√©n√©ralement de la mani√®re suivante, on commence par entra√Æner uniquement la partie classificatrice en gelant (freeze) les poids de la partie convolutive (qui sont normalement quasi-optimaux), cette partie est nomm√©e tuning. Une fois le classificateur bien entra√Æn√©, nous d√©gelons (unfreeze) les couches (par paquets ou toutes d‚Äôun coup) puis nous continuons l‚Äôentra√Ænement, cette partie est nomm√©e fine-tuning. De plus, nous utilisons un learning rate plus faible lors de cette phase afin d‚Äôajuster plus finement les poids d√©j√† quasi-optimaux.""")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2: 
        st.title("Preprocessing")
        st.write("")
        st.write("""Les mod√®les pr√©-entrain√©s que l‚Äôon utilise ont √©t√© entrain√©s sur des images d‚Äôun format sp√©cifique. Pour que le transfer learning ait du sens, il √©tait indispensable d‚Äôutiliser ce m√™me format pour nos images. Ainsi, nos images sont toujours redimensionn√©es √† la taille 224x224 (valeur couramment utilis√©e pour les mod√®les pr√©-entrain√©s), la valeur des pixels est r√©√©chelonn√©es entre 0 et 1 puis les 3 canaux RGB sont renormalis√©s pour observer la m√™me distribution que les images de ImageNet, i.e.  et .""")
        st.write("")
        st.write("")
        st.write("""Un des principaux d√©fauts des mod√®les de Deep Learning est qu‚Äôils ont tendance √† overfit en raison du tr√®s grand nombre de param√®tres. Une des solutions pour pallier ce probl√®me est le Data Augmentation. Cette pratique consiste √† d√©grader les images du jeu d‚Äôentrainement afin de permettre au mod√®le de g√©n√©raliser le plus possible. Il existe de nombreuses techniques de Data Augmentation, parmi les plus courantes, nous retrouvons la rotation, la translation, le retournement, le floutage, etc. Ci-dessous, nous pr√©sentons un exemple de Data Augmentation que nous avons utilis√©s sur nos images. """)
        st.write("")
        st.write("")
        
    c1,c2,c3 = st.columns([0.5,1,0.5])
    with c2:
        st.image(read_image_bucket( image_path + 'Data_augmentation.png'),channels="RGB", output_format="auto", use_column_width=True)

    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2: 
        st.title("Architecture")
        st.write("")
        st.write("""Dans le cadre du transfer learning, la partie convolutive du mod√®le est d√©termin√©e par le mod√®le pr√©-entrain√© que nous allons utiliser. Cependant, il reste √† d√©finir l‚Äôarchitecture de la partie Classifieur. Dans notre cas, nous avons choisi de travailler avec des r√©seaux de neurones denses. Nous avons ensuite r√©alis√© un travail d‚Äôoptimisation de l‚Äôarchitecture qui a consist√© √† tester diff√©rentes configurations afin de trouver celle qui donne les meilleurs r√©sultats (notons qu‚Äôune telle √©tude doit √™tre faite apr√®s le choix du mod√®le pr√©-entrain√©). Les travaux effectu√©s sont pr√©sent√©s en d√©tail dans notre rapport (disponible ici). Dans le cadre de notre projet nous avons test√© deux mod√®les pr√©-entrain√©s¬†: VGG19 et DenseNet161. Nous pr√©sentons dans la figure ci-dessous l‚Äôarchitecture retenue pour le mod√®le VGG19 et DenseNet161.""")
        st.write("")
        st.write("")
    expander = st.expander("Architecture")
    with st.expander("Architecture") : 
        col1, col2, col3 = st.columns([1,5,1])    
        with col2:
            st.subheader("DenseNet")
            st.image(read_image_bucket( image_path + 'Densenet161.png'),channels="RGB", output_format="auto", width=1000)
            st.write("")
            st.subheader("VGG19")
            st.image(read_image_bucket( image_path + 'VGG19.png'),channels="RGB", output_format="auto", width=1000)
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2: 
        st.title("Hyperparam√®tres")
        st.write("")
        st.write("""Les performances des mod√®les sont intrins√®quement li√©es √† la bonne s√©lection de ses hyperparam√®tres. Plusieurs hyperparam√®tres ont √©t√© test√©s et les r√©sultats sont pr√©sent√©s dans le rapport. Nous allons revenir dans la suite sur l‚Äôhyperparam√®tre le plus important¬†: le learning rate.""")
        st.write("")
        st.write("")
    col5, col6, col7, col8 = st.columns([0.5,4,4,0.5])
    with col7:
        st.write("""Le choix d'un learning rate optimal d√©pend de la topologie de la fonction de perte, qui est elle-m√™me fonction de l'ensemble des donn√©es et de l'architecture. Pour trouver le learning rate optimal, il est possible de r√©aliser plusieurs exp√©riences et d'analyser les r√©sultats un par un. Cependant, cela prend beaucoup de temps. Heureusement, dans Fastai, il existe une fonction de recherche de learning rate appel√©e lr_find, qui effectue essentiellement une exp√©rience simple o√π le learning rate est progressivement augment√© apr√®s chaque mini batch, tout en enregistrant la fonction de perte √† chaque it√©ration. La repr√©sentation graphique des pertes en fonction du taux d'apprentissage nous donnera une id√©e de l'√©volution de la fonction de perte et pourra √™tre utilis√©e comme point de d√©part pour trouver notre taux d'apprentissage optimal. La figure suivante montre la courbe obtenu gr√¢ce √† la fonction lr_find. 
 """)
        st.write("")
        st.write("")
       
    with col6:
        st.image(read_image_bucket( image_path + 'lr_find.png'),channels="RGB", output_format="auto")
    st.markdown("""---""")

    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2: 
        st.title("Entrainement")
        st.write("")
        st.write("""L‚Äôarchitecture et les hyperparam√®tres ayant √©t√© optimis√©, nous pouvions entreprendre l‚Äôentrainement du mod√®le. Apr√®s l‚Äôavoir test√©, nous avons choisis d‚Äôutiliser une m√©thode particuli√®re de learning rates scheduler (fonction qui permet de changer le learning rate au cours de l‚Äôentrainement) nomm√© one cycle fit, disponible dans la biblioth√®que Fastai, et d√©crite dans l‚Äôarticle de 2018 de Smith et al. [https://arxiv.org/pdf/1708.07120.pdf].""")
        st.write("")
        st.write("")
        st.write("""Le principe est d‚Äôaugmenter puis de diminuer le learning rate au cours de l‚Äôentrainement comme repr√©sent√© sur la figure ci-dessous.""")
        st.write("")
        st.write("")
    col5, col6, col7, col8 = st.columns([0.5,4,4,0.5])
    with col7:
        st.write("")
        st.write("")
        st.write("")
        st.write("""Cette m√©thode permet de faire converger les mod√®les plus rapidement et permet d‚Äôexplorer des learning rate plus grands au cours de l‚Äôentrainement (le  peut √™tre un ordre de grandeur plus grand que le learning rate optimal) ce qui constitue une m√©thode de r√©gularisation r√©duisant l‚Äôoverfitting. Cette m√©thode a √©t√© utilis√©e pour le mod√®le Densenet161 (entrain√© sur Fastai). Pour le mod√®le VGG19 (entrain√© sur Keras) nous avons utilis√© un scheduler qui diminue le learning rates petit √† petit au cours de l‚Äôentrainement. """)
        st.write("")
        st.write("")  
    with col6:
        st.image(read_image_bucket( image_path + 'one_cycle_fit.png'),channels="RGB", output_format="auto")
    st.markdown("""---""")
    
    col1, col2, col3 = st.columns([0.5,8,0.5])    
    with col2: 
        st.write("""Finalement, nous avons entrain√©s notre mod√®le avec les param√®tres suivants¬†:""")
        expander = st.expander("R√©sultats")
    col1, col2, col3 = st.columns([1,2,1])    
    with col2:
        with st.expander("R√©sultats"):
            tab1,tab2= st.tabs(["VGG19", "Densenet161"])
            with tab2: 
                st.image(read_image_bucket( image_path + 'train_densenet.png'),channels="RGB", output_format="auto")
            with tab1: 
                st.image(read_image_bucket( image_path + 'train_vgg19.png'),channels="RGB", output_format="auto")
            
                
    st.write("")
    st.write("")
    st.markdown("""---""")
    
    c1,c2,c3 = st.columns([0.5,8,0.5])
    with c2: 
        st.write("""La figure ci-dessous montre l‚Äô√©volution des loss, validation loss et validation accuracy au cours de l‚Äôentrainement. Nous observons que le mod√®le overfit l√©g√®rement en fin d‚Äôentrainement. Le r√©sultat final obtenu est une Top-1 Accuracy de 86.2% et une Top-5 Accuracy de 96.3% sur le jeu de validation et Top-1 Accuracy de 88.2% et une Top-5 Accuracy de 97.2% sur un jeu de test constitu√© de 2917 images r√©parties √©quilibr√®rent entre chaque classe.""")

    expander = st.expander("R√©sultats")
    with st.expander("R√©sultats"):
        tab1,tab2= st.tabs(["Densenet", "VGG19"])
        with tab1: 
            c1,c2,c3 = st.columns([1,6,1])
            with c2: 
                st.image(read_image_bucket( image_path + 'dense_loss_val_acc_100_2.png'),channels="RGB", output_format="auto", width=1000)
        
        with tab2:
            c1,c2,c3 = st.columns([1,6,1])
            with c2: 
                st.image(read_image_bucket( image_path + 'VGG19_loss_val_acc_100_2.png'),channels="RGB", output_format="auto", width=1000)
    c1,c2,c3 = st.columns([0.5,0.5,0.5])
    with c2: 
        st.image(read_image_bucket( image_path + 'comp_vgg_dense.png'),channels="RGB", output_format="auto", width=500)
    st.markdown("""---""")

if choice == 'Interpr√©tabilit√©':
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title('Rapport de projet')
        c1, c2, c3, c4 = st.columns(4, gap="large")
    st.markdown("""---""")


    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.title('Interpr√©tabilit√© du mod√®le')
        st.write("")
        st.write("""Nous avons mis en place deux outils afin de tenter de comprendre comment le mod√®le identifie un champignon sur une image¬†: le grad-CAM et le Guided Backpropagation. Ci-dessous nous montrons ces deux outils en action.""")
        st.write("")
        st.write("")
        st.image(read_image_bucket( image_path + 'top_amanita.png'),channels="RGB", output_format="auto")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2: 
        st.write("")  
        st.write("")  
        st.write("""Le grad-CAM est une m√©thode basse r√©solution tr√®s discriminante en termes de classe qui permet rapidement de voir que le mod√®le ne regarde pas autre chose que le champignon. Le Guided Backpropagation, quant √† lui, est √† haute r√©solution mais ne permet pas de discriminer les classes (il met en valeur les pixels important lors de la pr√©diction). Ces outils nous on permis de valider le mod√®le et, dans certaines situations, de comprendre les mauvaises pr√©dictions du mod√®le comme nous allons le voir dans la suite.""")
        st.write("")
        st.write("")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.title('Interpr√©tabilit√© des r√©sultats')
        st.write("")
        st.write("""Le rapport de classification ci-dessus montre des r√©sultats assez h√©t√©rog√®nes, certaines classes sont tr√®s bien pr√©dites alors que d‚Äôautres le sont moins""")
        st.write("")
        st.write("")
        st.write("""La matrice de confusion (difficilement affichable pour 100 classes) permet de trouver les classes les plus confuses. Le tableau ci-dessous montre les 5 premiers √©l√©ments non diagonaux les plus grands, nous donnons le vrai label, la pr√©diction ainsi que le nombre d‚Äôoccurrences.""")

    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.write("""Une exploration des images disponibles montre que ces esp√®ces se ressemblent morphologiquement. Ce qui explique pourquoi le mod√®le peine √† bien les distinguer. La figure ci-dessous montre les similitudes entre ces classes.""")
        st.write("")
        st.write("")
    st.markdown("""---""")
    col1, col2, col3 = st.columns([0.5,8,0.5])
    with col2:   
        st.write("""Une autre raison qui limite les r√©sultats du mod√®le sont les images mal labelis√©es. Soit le champignon sur l‚Äôimage ne correspond pas au label, soit il est tr√®s difficile voire impossible de le distinguer sur l‚Äôimage. Voici quelques exemples.""")
        st.write("")
        st.write("")
        expander = st.expander("Exemples")
        with st.expander("Exemples"): 
            tab1, tab2, tab3 = st.tabs(["top_loss_1", "top_loss_2", "top_loss_3"])
            with tab1:
                c1,c2,c3 = st.columns([0.5,2,0.5])
                with c2: 
                    st.image(read_image_bucket( image_path + 'top_loss_1.png'),channels="RGB", output_format="auto")
                st.write("")
                st.write("")
                st.subheader("Interpr√©tation ")
                st.write("")
                st.write("")
                st.write("""Ici on ne sait pas vraiment s‚Äôil y a un champignon sur l‚Äôimage. Le mod√®le fait tout de m√™me une pr√©diction avec une probabilit√© de 77%. L‚Äôoutil Guided Backpropagtion permet de comprendre la pr√©diction. En effet, le mod√®le semble se concentrer sur des feuilles, dont la forme ressemble fortement √† la classe pr√©dite.""")
            
            with tab2:
                c1,c2,c3 = st.columns([0.5,2,0.5])
                with c2:
                    st.image(read_image_bucket( image_path + 'top_loss_2.png'),channels="RGB", output_format="auto")
                st.write("")
                st.write("")
                st.subheader("Interpr√©tation¬† ")
                st.write("")
                st.write("")
                st.write("""Ici l‚Äôimage semble mal lab√©lis√©e. Le champignon ne ressemble pas aux autres champignons de m√™me label. Cependant, nous observons des similitudes avec les champignons de la classe pr√©dite.""")
            
            with tab3:
                c1,c2,c3 = st.columns([0.5,2,0.5])
                with c2:
                    st.image(read_image_bucket( image_path + 'top_loss_3.png'),channels="RGB", output_format="auto")
                st.write("")
                st.write("")
                st.subheader("Interpr√©tation¬† ")
                st.write("")
                st.write("")
                st.write("""Ici il y a deux champignons diff√©rents sur l‚Äôimage. Le grad-CAM permet de de voir que le mod√®le fait une pr√©diction sur le champignon orange qui semble correct. Cependant, l‚Äôimage a √©t√©  labelis√©e Exidia glandulosa (champignon noir). Ce qui explique pourquoi cette image est mal pr√©dite.""")

